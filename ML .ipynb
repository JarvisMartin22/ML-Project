{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurricane Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import calendar\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from textblob import TextBlob, Word\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Set is webscraped Tornados in US, from 1950 - 2018\n",
    "\n",
    "Dummies\n",
    "regression \n",
    "Random Forest\n",
    "confusion matrix \n",
    "Gridsearch\n",
    "compile model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>TOR_F_SCALE</th>\n",
       "      <th>TOR_LENGTH</th>\n",
       "      <th>TOR_WIDTH</th>\n",
       "      <th>Duration</th>\n",
       "      <th>AverageDate</th>\n",
       "      <th>AverageTime</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Injuries</th>\n",
       "      <th>Mean_Lat</th>\n",
       "      <th>Mean_Lon</th>\n",
       "      <th>Azimuth</th>\n",
       "      <th>State</th>\n",
       "      <th>PropertyDamageCost</th>\n",
       "      <th>CropsDamageCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Law_Enforcement</td>\n",
       "      <td>EF0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>15.685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.2945</td>\n",
       "      <td>-98.6804</td>\n",
       "      <td>1.11</td>\n",
       "      <td>KS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Broadcast_Media</td>\n",
       "      <td>EF0</td>\n",
       "      <td>1.38</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5</td>\n",
       "      <td>183</td>\n",
       "      <td>17.535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.7200</td>\n",
       "      <td>-80.2500</td>\n",
       "      <td>0.00</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Storm_Chaser</td>\n",
       "      <td>EF0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9</td>\n",
       "      <td>111</td>\n",
       "      <td>18.875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.6830</td>\n",
       "      <td>-98.3963</td>\n",
       "      <td>81.93</td>\n",
       "      <td>SD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NWS_Storm_Survey</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>11.925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.6658</td>\n",
       "      <td>-81.5240</td>\n",
       "      <td>-36.57</td>\n",
       "      <td>FL</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NWS_Storm_Survey</td>\n",
       "      <td>EF2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>6.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5300</td>\n",
       "      <td>-82.2500</td>\n",
       "      <td>64.36</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            SOURCE TOR_F_SCALE  TOR_LENGTH  TOR_WIDTH  Duration  \\\n",
       "0           0   Law_Enforcement         EF0        1.43       50.0         3   \n",
       "1           1   Broadcast_Media         EF0        1.38       20.0         5   \n",
       "2           2      Storm_Chaser         EF0        2.77      100.0         9   \n",
       "3           3  NWS_Storm_Survey         EF0        0.55       30.0         1   \n",
       "4           4  NWS_Storm_Survey         EF2        1.50      300.0         0   \n",
       "\n",
       "   AverageDate  AverageTime  Deaths  Injuries  Mean_Lat  Mean_Lon  Azimuth  \\\n",
       "0          126       15.685       0         0   37.2945  -98.6804     1.11   \n",
       "1          183       17.535       0         0   26.7200  -80.2500     0.00   \n",
       "2          111       18.875       0         0   43.6830  -98.3963    81.93   \n",
       "3          152       11.925       0         0   24.6658  -81.5240   -36.57   \n",
       "4          105        6.250       0         0   30.5300  -82.2500    64.36   \n",
       "\n",
       "  State  PropertyDamageCost  CropsDamageCost  \n",
       "0    KS                   0                0  \n",
       "1    FL                   0                0  \n",
       "2    SD                   0                0  \n",
       "3    FL               20000                0  \n",
       "4    FL                   0                0  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Data by connecting to storms Database With SQLalchemy\n",
    "Tornado = pd.read_csv('Resources/CleanTornado2.csv')\n",
    "Tornado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop rows that have nan\n",
    "# Tornado.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tornado = Tornado.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = Tornado.reset_index().TOR_F_SCALE\n",
    "X1 = Tornado.reset_index().drop(['TOR_F_SCALE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOR_LENGTH</th>\n",
       "      <th>TOR_WIDTH</th>\n",
       "      <th>Duration</th>\n",
       "      <th>AverageDate</th>\n",
       "      <th>AverageTime</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Injuries</th>\n",
       "      <th>Mean_Lat</th>\n",
       "      <th>Mean_Lon</th>\n",
       "      <th>Azimuth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.384696</td>\n",
       "      <td>-0.453753</td>\n",
       "      <td>-0.372725</td>\n",
       "      <td>-0.399389</td>\n",
       "      <td>0.034001</td>\n",
       "      <td>-0.046745</td>\n",
       "      <td>-0.057794</td>\n",
       "      <td>0.025597</td>\n",
       "      <td>-0.818166</td>\n",
       "      <td>-1.299679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.396503</td>\n",
       "      <td>-0.557985</td>\n",
       "      <td>-0.080881</td>\n",
       "      <td>0.326020</td>\n",
       "      <td>0.391832</td>\n",
       "      <td>-0.046745</td>\n",
       "      <td>-0.057794</td>\n",
       "      <td>-2.195896</td>\n",
       "      <td>1.453279</td>\n",
       "      <td>-1.324643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOR_LENGTH  TOR_WIDTH  Duration  AverageDate  AverageTime    Deaths  \\\n",
       "0   -0.384696  -0.453753 -0.372725    -0.399389     0.034001 -0.046745   \n",
       "1   -0.396503  -0.557985 -0.080881     0.326020     0.391832 -0.046745   \n",
       "\n",
       "   Injuries  Mean_Lat  Mean_Lon   Azimuth  \n",
       "0 -0.057794  0.025597 -0.818166 -1.299679  \n",
       "1 -0.057794 -2.195896  1.453279 -1.324643  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing numerical features:\n",
    "numfeat = ['TOR_LENGTH', 'TOR_WIDTH', 'Duration', 'AverageDate', 'AverageTime', \n",
    "           'Deaths', 'Injuries', 'Mean_Lat', 'Mean_Lon', 'Azimuth']\n",
    "scaler = StandardScaler()\n",
    "X1numfeat = pd.DataFrame(scaler.fit_transform(X1[numfeat]), columns=numfeat)\n",
    "X1numfeat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16353, 6) (16353,)\n"
     ]
    }
   ],
   "source": [
    "# x = Tornado.reset_index().drop(['TOR_F_SCALE'],axis=1)\n",
    "# y = Tornado.reset_index().TOR_F_SCALE\n",
    "# print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TX    1551\n",
       "KS    1227\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tornado.State.value_counts().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NWS_Storm_Survey    10349\n",
       "Trained_Spotter      1167\n",
       "Name: SOURCE, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tornado.SOURCE.value_counts().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_AL</th>\n",
       "      <th>State_AR</th>\n",
       "      <th>State_AZ</th>\n",
       "      <th>State_CA</th>\n",
       "      <th>State_CO</th>\n",
       "      <th>State_CT</th>\n",
       "      <th>State_DC</th>\n",
       "      <th>State_DE</th>\n",
       "      <th>State_FL</th>\n",
       "      <th>State_GA</th>\n",
       "      <th>...</th>\n",
       "      <th>Source_Official_NWS_Observations</th>\n",
       "      <th>Source_Other_Federal_Agency</th>\n",
       "      <th>Source_Park/Forest_Service</th>\n",
       "      <th>Source_Public</th>\n",
       "      <th>Source_Social_Media</th>\n",
       "      <th>Source_State_Official</th>\n",
       "      <th>Source_Storm_Chaser</th>\n",
       "      <th>Source_Trained_Spotter</th>\n",
       "      <th>Source_Unknown</th>\n",
       "      <th>Source_Utility_Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State_AL  State_AR  State_AZ  State_CA  State_CO  State_CT  State_DC  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "\n",
       "   State_DE  State_FL  State_GA           ...            \\\n",
       "0         0         0         0           ...             \n",
       "1         0         1         0           ...             \n",
       "\n",
       "   Source_Official_NWS_Observations  Source_Other_Federal_Agency  \\\n",
       "0                                 0                            0   \n",
       "1                                 0                            0   \n",
       "\n",
       "   Source_Park/Forest_Service  Source_Public  Source_Social_Media  \\\n",
       "0                           0              0                    0   \n",
       "1                           0              0                    0   \n",
       "\n",
       "   Source_State_Official  Source_Storm_Chaser  Source_Trained_Spotter  \\\n",
       "0                      0                    0                       0   \n",
       "1                      0                    0                       0   \n",
       "\n",
       "   Source_Unknown  Source_Utility_Company  \n",
       "0               0                       0  \n",
       "1               0                       0  \n",
       "\n",
       "[2 rows x 76 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdummies = pd.get_dummies(X1[['State','SOURCE']], prefix=['State','Source'],\n",
    "                        columns=['State','SOURCE'])\n",
    "Xdummies.drop(['State_TX','Source_NWS_Storm_Survey'], axis=1, inplace=True)\n",
    "Xdummies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16353, 86) (16353, 10) (16353, 76)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOR_LENGTH</th>\n",
       "      <th>TOR_WIDTH</th>\n",
       "      <th>Duration</th>\n",
       "      <th>AverageDate</th>\n",
       "      <th>AverageTime</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Injuries</th>\n",
       "      <th>Mean_Lat</th>\n",
       "      <th>Mean_Lon</th>\n",
       "      <th>Azimuth</th>\n",
       "      <th>...</th>\n",
       "      <th>Source_Official_NWS_Observations</th>\n",
       "      <th>Source_Other_Federal_Agency</th>\n",
       "      <th>Source_Park/Forest_Service</th>\n",
       "      <th>Source_Public</th>\n",
       "      <th>Source_Social_Media</th>\n",
       "      <th>Source_State_Official</th>\n",
       "      <th>Source_Storm_Chaser</th>\n",
       "      <th>Source_Trained_Spotter</th>\n",
       "      <th>Source_Unknown</th>\n",
       "      <th>Source_Utility_Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.384696</td>\n",
       "      <td>-0.453753</td>\n",
       "      <td>-0.372725</td>\n",
       "      <td>-0.399389</td>\n",
       "      <td>0.034001</td>\n",
       "      <td>-0.046745</td>\n",
       "      <td>-0.057794</td>\n",
       "      <td>0.025597</td>\n",
       "      <td>-0.818166</td>\n",
       "      <td>-1.299679</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.396503</td>\n",
       "      <td>-0.557985</td>\n",
       "      <td>-0.080881</td>\n",
       "      <td>0.326020</td>\n",
       "      <td>0.391832</td>\n",
       "      <td>-0.046745</td>\n",
       "      <td>-0.057794</td>\n",
       "      <td>-2.195896</td>\n",
       "      <td>1.453279</td>\n",
       "      <td>-1.324643</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOR_LENGTH  TOR_WIDTH  Duration  AverageDate  AverageTime    Deaths  \\\n",
       "0   -0.384696  -0.453753 -0.372725    -0.399389     0.034001 -0.046745   \n",
       "1   -0.396503  -0.557985 -0.080881     0.326020     0.391832 -0.046745   \n",
       "\n",
       "   Injuries  Mean_Lat  Mean_Lon   Azimuth           ...            \\\n",
       "0 -0.057794  0.025597 -0.818166 -1.299679           ...             \n",
       "1 -0.057794 -2.195896  1.453279 -1.324643           ...             \n",
       "\n",
       "   Source_Official_NWS_Observations  Source_Other_Federal_Agency  \\\n",
       "0                                 0                            0   \n",
       "1                                 0                            0   \n",
       "\n",
       "   Source_Park/Forest_Service  Source_Public  Source_Social_Media  \\\n",
       "0                           0              0                    0   \n",
       "1                           0              0                    0   \n",
       "\n",
       "   Source_State_Official  Source_Storm_Chaser  Source_Trained_Spotter  \\\n",
       "0                      0                    0                       0   \n",
       "1                      0                    0                       0   \n",
       "\n",
       "   Source_Unknown  Source_Utility_Company  \n",
       "0               0                       0  \n",
       "1               0                       0  \n",
       "\n",
       "[2 rows x 86 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = pd.concat([X1numfeat,X1dums], axis=1)\n",
    "print(X1.shape, X1numfeat.shape, X1dums.shape)\n",
    "X1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain1, Xtest1, ytrain1, ytest1 = train_test_split(X1, y1, test_size=0.3, \n",
    "                                                    stratify=y1, random_state=31)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytest1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.527"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test1 = ytest1.value_counts()\n",
    "accuracy_baseline = ytest_valcounts.get_values()[0]/float(ytest_valcounts.get_values().sum())\n",
    "round(accuracy_baseline, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.669"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LordOfTheRings1 = LogisticRegression()\n",
    "accuracy_cv5_lr1 = np.mean(cross_val_score(lr1, Xtrain1, ytrain1, cv=5))\n",
    "round(accuracy_cv5_lr1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRIDSEARCHING\n",
    "target_names = [\"negative\", \"positive\"]\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "              'gamma': [0.0001, 0.001, 0.01]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=1, gamma=0.0001, score=0.6733892090099528, total=   7.2s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=1, gamma=0.0001, score=0.6771488469601677, total=   7.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   21.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=1, gamma=0.0001, score=0.6923682140047207, total=   6.9s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.6733892090099528, total=   6.7s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.6771488469601677, total=   6.6s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.6923682140047207, total=   6.5s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6733892090099528, total=   6.5s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6771488469601677, total=   7.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6923682140047207, total=   7.2s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ...... C=5, gamma=0.0001, score=0.6720796228391828, total=   9.7s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ....... C=5, gamma=0.0001, score=0.679769392033543, total=  10.0s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ...... C=5, gamma=0.0001, score=0.6918436926304747, total=   9.7s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] ....... C=5, gamma=0.001, score=0.6720796228391828, total=   9.9s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] ........ C=5, gamma=0.001, score=0.679769392033543, total=   9.9s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] ....... C=5, gamma=0.001, score=0.6918436926304747, total=   9.6s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ........ C=5, gamma=0.01, score=0.6720796228391828, total=   9.8s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ......... C=5, gamma=0.01, score=0.679769392033543, total=   9.8s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ........ C=5, gamma=0.01, score=0.6918436926304747, total=   9.6s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0001, score=0.6726034573074908, total=  13.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0001, score=0.6787211740041929, total=  14.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ..... C=10, gamma=0.0001, score=0.6913191712562287, total=  12.6s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6726034573074908, total=  13.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6787211740041929, total=  12.3s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6913191712562287, total=  12.6s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6726034573074908, total=  13.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6787211740041929, total=  12.3s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6913191712562287, total=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(Xtrain1, ytrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'gamma': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "# rf3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6812265222328995\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(Xtest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.75      0.89      0.81      2585\n",
      "                   0.58      0.58      0.58      1642\n",
      "                   0.48      0.16      0.24       475\n",
      "                   0.66      0.17      0.27       134\n",
      "                   0.50      0.16      0.24        31\n",
      "                   0.25      0.25      0.25         4\n",
      "                   0.00      0.00      0.00        35\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      4906\n",
      "   macro avg       0.46      0.32      0.34      4906\n",
      "weighted avg       0.66      0.68      0.66      4906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest1, predictions,\n",
    "                            target_names=[\"\", \"\",\"\",\"\",\"\",\"\",\"\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7107623318385651"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(Xtrain1, ytrain1)\n",
    "rf.score(Xtest1, ytest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = Tornado.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1689570409196131, 'Unnamed: 0'),\n",
       " (0.1355325774919336, 'index'),\n",
       " (0.09864231898682205, 'AverageTime'),\n",
       " (0.08671300133691014, 'TOR_LENGTH'),\n",
       " (0.08546702735477035, 'AverageDate'),\n",
       " (0.08165813154280734, 'Deaths'),\n",
       " (0.07789314343330338, 'TOR_F_SCALE'),\n",
       " (0.07662290487273073, 'SOURCE'),\n",
       " (0.03359488250934145, 'Duration'),\n",
       " (0.008739241547408893, 'TOR_WIDTH'),\n",
       " (0.004960758569090923, 'Injuries'),\n",
       " (0.0043782708371434545, 'Mean_Lat'),\n",
       " (0.0022370042242946084, 'State'),\n",
       " (0.0005071796426377615, 'PropertyDamageCost'),\n",
       " (0.0004901953433404987, 'Azimuth'),\n",
       " (0.0002526743473104833, 'Mean_Lon'),\n",
       " (2.259928324721365e-05, 'CropsDamageCost')]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler and y_scaler models\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-45c0b357a078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 458\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Create a LinearRegression model and fit it to the scaled training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
